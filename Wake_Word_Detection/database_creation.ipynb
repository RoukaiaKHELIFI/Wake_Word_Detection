{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs.client import ElevenLabs\n",
    "from elevenlabs import play, save\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = ElevenLabs(api_key=os.getenv(\"ELEVEN_LABS_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All the Voices from the official website\n",
    "Because trying to get it from the library itself will only give me the default voices without including the legacy voices too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>voice_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>accent</th>\n",
       "      <th>description</th>\n",
       "      <th>use_case</th>\n",
       "      <th>preview_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>Xb7hH8MSUJpSbSDYk0k2</td>\n",
       "      <td>female</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>British</td>\n",
       "      <td>confident</td>\n",
       "      <td>news</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aria</td>\n",
       "      <td>9BWtsMINqrJLrRacOk9x</td>\n",
       "      <td>female</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>American</td>\n",
       "      <td>expressive</td>\n",
       "      <td>social media</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill</td>\n",
       "      <td>pqHfZKP75CvOlQylNhV4</td>\n",
       "      <td>male</td>\n",
       "      <td>old</td>\n",
       "      <td>American</td>\n",
       "      <td>trustworthy</td>\n",
       "      <td>narration</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brian</td>\n",
       "      <td>nPczCjzI2devNBz1zQrb</td>\n",
       "      <td>male</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>American</td>\n",
       "      <td>deep</td>\n",
       "      <td>narration</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Callum</td>\n",
       "      <td>N2lVS1w4EtoT3dr4eOWO</td>\n",
       "      <td>male</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>Transatlantic</td>\n",
       "      <td>intense</td>\n",
       "      <td>characters</td>\n",
       "      <td>Sample</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name              voice_id  gender          age         accent  \\\n",
       "0   Alice  Xb7hH8MSUJpSbSDYk0k2  female  middle-aged        British   \n",
       "1    Aria  9BWtsMINqrJLrRacOk9x  female  middle-aged       American   \n",
       "2    Bill  pqHfZKP75CvOlQylNhV4    male          old       American   \n",
       "3   Brian  nPczCjzI2devNBz1zQrb    male  middle-aged       American   \n",
       "4  Callum  N2lVS1w4EtoT3dr4eOWO    male  middle-aged  Transatlantic   \n",
       "\n",
       "   description      use_case preview_url  \n",
       "0    confident          news      Sample  \n",
       "1   expressive  social media      Sample  \n",
       "2  trustworthy     narration      Sample  \n",
       "3         deep     narration      Sample  \n",
       "4      intense    characters      Sample  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Send a GET request to the page\n",
    "url = \"https://elevenlabs.io/docs/voices/default-voices\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 2: Parse the HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 3: Find the specific tables\n",
    "tables = soup.find_all('table', {'width': '100%', 'height': '500'})\n",
    "\n",
    "# List to store extracted data\n",
    "all_data = []\n",
    "\n",
    "# Step 4: Process each table found\n",
    "for table in tables:\n",
    "    # Step 4.1: Extract headers if they exist\n",
    "    headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
    "    \n",
    "    # If no headers found, skip this table (assuming it's essential for structure)\n",
    "    if not headers:\n",
    "        continue\n",
    "\n",
    "    # Step 4.2: Extract data rows from the table\n",
    "    rows_data = []\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cells = [cell.get_text(strip=True) for cell in row.find_all('td')]\n",
    "        if cells:\n",
    "            rows_data.append(cells)\n",
    "    \n",
    "    # Step 4.3: Create a DataFrame for the current table\n",
    "    if rows_data:\n",
    "        df = pd.DataFrame(rows_data, columns=headers)  # Assign headers as column names\n",
    "        all_data.append(df)\n",
    "\n",
    "# Step 5: Combine all extracted tables into one DataFrame\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('ElevenLabs_All_Voices.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ElevenLabs_All_Voices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the \"Hey Shadow\" Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing of all possible variations of \"Hey shadow\"\n",
    "text_variations = [\"Hey Shadow!\", \"Hey shadow\", \"Hey Shadow\", \"hey shadow\", \"hey shadow!\", \"hey shadow ?\", \"Hey shadow ?\"]\n",
    "\n",
    "def GenerateDataset(df, num_variations=5):\n",
    "\n",
    "    output_dir = \"hey_shadow_dataset\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through each voice ID in the dataframe\n",
    "    for voice_id in df['voice_id']:\n",
    "        # Generate multiple audio files for each voice\n",
    "        for i in range(num_variations):\n",
    "            # Select a random variation of the text\n",
    "            text = random.choice(text_variations)\n",
    "            \n",
    "            # Generate the audio with the selected voice ID and text\n",
    "            audio = client.generate(\n",
    "                text=text,\n",
    "                voice=voice_id\n",
    "            )\n",
    "            \n",
    "            # Save the audio file with a unique name\n",
    "            file_path = os.path.join(output_dir, f\"hey_shadow_{voice_id}_{i}.mp3\")\n",
    "            save(audio, file_path)\n",
    "\n",
    "# Generating the dataset with \"Hey Shadow\"\n",
    "# GenerateDataset(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "# calculate how many files we have in the directory hey_shadow_dataset\n",
    "path = 'hey_shadow_dataset'\n",
    "num_files = len(glob.glob1(path, \"*.mp3\"))\n",
    "print(num_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Random Words and phrases DataBase that are not related to \"Hey Shadow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of phrases unrelated to \"hey shadow\"\n",
    "not_hey_shadow_texts = [\n",
    "    \"Good morning!\",\n",
    "    \"Hello\",\n",
    "    \"Hello there\",\n",
    "    \"Good afternoon!\",\n",
    "    \"Good evening!\",\n",
    "    \"What time is it?\",\n",
    "    \"What's up?\",\n",
    "    \"how's the weather?\",\n",
    "    \"Thank you!\",\n",
    "    \"can you help me?\",\n",
    "    \"can you hear me?\"\n",
    "]\n",
    "\n",
    "# Number of samples to generate for \"not_hey_shadow\" dataset\n",
    "target_samples = 262\n",
    "\n",
    "def GenerateNotHeyShadowDataset(df, target_samples):\n",
    "    output_dir = \"not_hey_shadow_dataset\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Total samples created so far\n",
    "    samples_created = 0\n",
    "\n",
    "    # Loop through each voice ID and generate clips until reaching target samples\n",
    "    while samples_created < target_samples:\n",
    "        for voice_id in df['voice_id']:\n",
    "            # Stop if target samples is reached\n",
    "            if samples_created >= target_samples:\n",
    "                break\n",
    "            \n",
    "            # Select a random phrase from the unrelated text list\n",
    "            text = random.choice(not_hey_shadow_texts)\n",
    "            \n",
    "            # Generate the audio with the selected voice ID and text\n",
    "            audio = client.generate(\n",
    "                text=text,\n",
    "                voice=voice_id\n",
    "            )\n",
    "            \n",
    "            # Save the audio file with a unique name in the new directory\n",
    "            file_path = os.path.join(output_dir, f\"not_hey_shadow_{voice_id}_{samples_created}.mp3\")\n",
    "            save(audio, file_path)\n",
    "            \n",
    "            # Increment the samples counter\n",
    "            samples_created += 1\n",
    "\n",
    "\n",
    "GenerateNotHeyShadowDataset(df, target_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the FFMPEG works or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if FFmpeg Framework works or not\n",
    "\n",
    "\n",
    "# import os\n",
    "# import subprocess\n",
    "\n",
    "# # Set the ffmpeg path in the environment variable for the duration of the script\n",
    "# os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\ffmpeg-2024-10-27-git-bb57b78013-full_build\\bin\"\n",
    "\n",
    "# from pydub import AudioSegment\n",
    "\n",
    "# # Load a single audio file as a test\n",
    "# try:\n",
    "#     audio = AudioSegment.from_file(r\"C:\\Users\\rouka\\Desktop\\hey_shadow\\hey_shadow_dataset\\hey_shadow_5Q0t7uMcjvnagumLfvZi_1.mp3\")\n",
    "#     print(f\"Loaded file duration: {len(audio)} milliseconds\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ffmpeg path in the environment variable for the duration of the script\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\ffmpeg\\ffmpeg-2024-10-27-git-bb57b78013-full_build\\bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepration (Adjusting all the voices to exactly 1 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustDuration(input_directory, output_directory, target_duration):\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            # Load the audio file\n",
    "            audio_path = os.path.join(input_directory, filename)\n",
    "            audio = AudioSegment.from_file(audio_path)\n",
    "\n",
    "            # Adjust the duration to exactly 1 second\n",
    "            if len(audio) > target_duration:\n",
    "                # Trim if audio is longer than 1 second\n",
    "                audio = audio[:target_duration]\n",
    "            else:\n",
    "                # Pad with silence if audio is shorter than 1 second\n",
    "                silence = AudioSegment.silent(duration=target_duration - len(audio))\n",
    "                audio = audio + silence\n",
    "\n",
    "            # Save the modified file to the output directory\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "            audio.export(output_path, format=\"mp3\")\n",
    "\n",
    "    print(\"All audio files have been adjusted to 1 second.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All audio files have been adjusted to 1 second.\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the audio files\n",
    "input_directory = r\"C:\\Users\\rouka\\Desktop\\hey_shadow\\hey_shadow_dataset\"\n",
    "output_directory = r\"C:\\Users\\rouka\\Desktop\\hey_shadow\\hey_shadow_dataset_1s\"\n",
    "# Desired duration in milliseconds\n",
    "target_duration = 1000\n",
    "AdjustDuration(input_directory, output_directory, target_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All audio files have been adjusted to 1 second.\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the audio files\n",
    "input_directory = r\"C:\\Users\\rouka\\Desktop\\hey_shadow\\not_hey_shadow_dataset\"\n",
    "output_directory = r\"C:\\Users\\rouka\\Desktop\\hey_shadow\\not_hey_shadow_dataset_1s\"\n",
    "# Desired duration in milliseconds\n",
    "target_duration = 1000\n",
    "AdjustDuration(input_directory, output_directory, target_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
